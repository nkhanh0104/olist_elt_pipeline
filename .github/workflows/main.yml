# The name of the workflow, which will be displayed on the GitHub Actions interface
name: Airflow CI/CD Pipeline

# Defines when this workflow will run
on:
  push:
    branches:
      - master # Run workflow when there is a push to the 'master' branch

# Define global environment variables for the workflow
# These variables will be available to all jobs.
# For sensitive variables, you SHOULD use GitHub Secrets.
env:
  # Variables related to Docker Registry and Airflow Image
  # These values will be taken from GitHub Secrets or GitHub Variables
  AIRFLOW_IMAGE_NAME: ghcr.io/${{ github.repository }}/airflow:latest # Ex: ghcr.io/your-github-username/your-repo/airflow:latest
  DOCKER_REGISTRY_URL: ${{ vars.DOCKER_REGISTRY_URL }} # Ex: ghcr.io

  # Airflow configuration variables (used in docker-compose.yml)
  AIRFLOW__CORE__EXECUTOR: ${{ vars.AIRFLOW__CORE__EXECUTOR }}
  AIRFLOW__CORE__FERNET_KEY: ${{ secrets.AIRFLOW__CORE__FERNET_KEY }}
  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${{ secrets.AIRFLOW__DATABASE__SQL_ALCHEMY_CONN }}
  AIRFLOW__CORE__DAGS_PAUSED_AT_CREATION: ${{ vars.AIRFLOW__CORE__DAGS_PAUSED_AT_CREATION }}
  AIRFLOW__CORE__LOAD_EXAMPLES: ${{ vars.AIRFLOW__CORE__LOAD_EXAMPLES }}
  AIRFLOW_UID: ${{ vars.AIRFLOW_UID }}
  AIRFLOW_GID: ${{ vars.AIRFLOW_GID }}
  AIRFLOW_USER: ${{ vars.AIRFLOW_USER }}
  AIRFLOW_PASSWORD: ${{ secrets.AIRFLOW_PASSWORD }}
  AIRFLOW_EMAIL: ${{ vars.AIRFLOW_EMAIL }}

  # Variables for Snowflake and Elementary (set into Airflow Variables)
  # These variables will be passed into the 'airflow variables set' commands
  DBT_FOLDER_NAME: ${{ vars.DBT_FOLDER_NAME }}
  DBT_PROJECT_NAME: ${{ vars.DBT_PROJECT_NAME }}
  ELEMENTARY_ACCOUNT: ${{ secrets.ELEMENTARY_ACCOUNT }}
  ELEMENTARY_DATABASE: ${{ vars.ELEMENTARY_DATABASE }}
  ELEMENTARY_ENV: ${{ vars.ELEMENTARY_ENV }}
  ELEMENTARY_PASSWORD: ${{ secrets.ELEMENTARY_PASSWORD }}
  ELEMENTARY_ROLE: ${{ vars.ELEMENTARY_ROLE }}
  ELEMENTARY_SCHEMA: ${{ vars.ELEMENTARY_SCHEMA }}
  ELEMENTARY_USER: ${{ secrets.ELEMENTARY_USER }}
  ELEMENTARY_WAREHOUSE: ${{ vars.ELEMENTARY_WAREHOUSE }}
  PROJECT_ROOT_DIR_AIRFLOW_VAR: ${{ vars.PROJECT_ROOT_DIR_AIRFLOW_VAR }}
  SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
  SNOWFLAKE_DATABASE: ${{ vars.SNOWFLAKE_DATABASE }}
  SNOWFLAKE_ENV: ${{ vars.SNOWFLAKE_ENV }}
  SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
  SNOWFLAKE_ROLE: ${{ vars.SNOWFLAKE_ROLE }}
  SNOWFLAKE_SCHEMA_MART: ${{ vars.SNOWFLAKE_SCHEMA_MART }}
  SNOWFLAKE_SCHEMA_RAW: ${{ vars.SNOWFLAKE_SCHEMA_RAW }}
  SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
  SNOWFLAKE_WAREHOUSE: ${{ vars.SNOWFLAKE_WAREHOUSE }}

# Define jobs in workflow
jobs:
  # Job to build and push Docker Image to Airflow
  build-airflow-image:
    runs-on: ubuntu-latest # Run on a GitHub-hosted runner
    permissions: # Grant packages: write permission to this job
      packages: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v4 # Action to clone repository

      - name: Log in to Docker Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.DOCKER_REGISTRY_URL }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push Airflow Docker image
        uses: docker/build-push-action@v5
        with:
          context: . # Path to Dockerfile (current directory)
          push: true # Push image to registry
          tags: ${{ env.AIRFLOW_IMAGE_NAME }} # Use image name from environment variable
          no-cache: true # Ensure completely new build

  # Job to deploy Airflow environment using Docker Compose
  deploy-airflow-environment:
    runs-on: ubuntu-latest # Run on a GitHub-hosted runner
    needs: build-airflow-image # Make sure this job runs after the image has been built
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Log in to Docker Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.DOCKER_REGISTRY_URL }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set permissions for Airflow logs directory # Create and grant permissions to the logs folder
        run: |
          mkdir -p ./logs
          chmod -R 777 ./logs # Grant full write permissions to avoid PermissionError

      - name: Start PostgreSQL and Wait for it to be ready # Just start Postgres first
        run: |
          echo "Starting PostgreSQL service..."
          docker compose up -d postgres
          echo "Waiting for PostgreSQL to be healthy..."
          for i in $(seq 1 10); do # Try up to 10 times (wait 10s each time, total 100s)
            if docker compose exec postgres pg_isready -U airflow -d airflow; then
              echo "PostgreSQL is ready!"
              break
            else
              echo "Waiting for PostgreSQL... ($i/10)"
              sleep 10
            fi
            if [ $i -eq 10 ]; then
              echo "Error: PostgreSQL did not become ready in time."
              docker compose logs postgres
              exit 1
            fi
          done

      - name: Initialize Airflow database and create admin user
        run: |
          echo "Initializing Airflow database and creating admin user..."
          # Run db upgrade and create user on webserver container
          docker compose run --rm airflow-webserver airflow db upgrade
          docker compose run --rm airflow-webserver airflow users create \
              --username ${{ vars.AIRFLOW_USER }} \
              --password ${{ secrets.AIRFLOW_PASSWORD }} \
              --firstname Admin \
              --lastname User \
              --role Admin \
              --email ${{ vars.AIRFLOW_EMAIL }} || true
          echo "Airflow database initialized and admin user created."

      - name: Start remaining Airflow services # Start webserver and scheduler
        run: |
          echo "Starting Airflow webserver and scheduler services..."
          docker compose up -d airflow-webserver airflow-scheduler
          echo "Airflow webserver and scheduler deployed."

      - name: Wait for Airflow webserver to be ready
        run: |
          echo "Waiting for Airflow webserver to be ready..."
          # Loop to check webserver health
          for i in $(seq 1 20); do # Try up to 20 times (wait 10s each time, total 200s)
            # Execute curl INSIDE the webserver container to check health.
            if docker compose exec airflow-webserver curl --fail http://localhost:8080/health; then 
              echo "Airflow webserver is ready!"
              break
            else
              echo "Waiting for Airflow webserver... ($i/20)"
              sleep 10
            fi
            if [ $i -eq 20 ]; then
              echo "Error: Airflow webserver did not become ready in time."
              exit 1 # Exit with error if not ready after multiple tries
            fi
          done

      - name: Set Airflow Variables
        run: |
          echo "Setting Airflow Variables from GitHub Actions Variables/Secrets..."
          # These variables will be provided by GitHub Actions as environment variables
          # in the container running this job.
          # We use 'docker compose exec' to run the command on the running webserver container.
          docker compose exec -T airflow-webserver airflow variables set DBT_FOLDER_NAME "$DBT_FOLDER_NAME"
          docker compose exec -T airflow-webserver airflow variables set DBT_PROJECT_NAME "$DBT_PROJECT_NAME"
          docker compose exec -T airflow-webserver airflow variables set DBT_VAR_DATE "$DBT_VAR_DATE"
          docker compose exec -T airflow-webserver airflow variables set DBT_VAR_MONTH "$DBT_VAR_MONTH"
          docker compose exec -T airflow-webserver airflow variables set DBT_VAR_QUARTER "$DBT_VAR_QUARTER"
          docker compose exec -T airflow-webserver airflow variables set DBT_VAR_YEAR "$DBT_VAR_YEAR"
          docker compose exec -T airflow-webserver airflow variables set ELEMENTARY_ACCOUNT "$ELEMENTARY_ACCOUNT"
          docker compose exec -T airflow-webserver airflow variables set ELEMENTARY_DATABASE "$ELEMENTARY_DATABASE"
          docker compose exec -T airflow-webserver airflow variables set ELEMENTARY_ENV "$ELEMENTARY_ENV"
          docker compose exec -T airflow-webserver airflow variables set ELEMENTARY_PASSWORD "$ELEMENTARY_PASSWORD"
          docker compose exec -T airflow-webserver airflow variables set ELEMENTARY_ROLE "$ELEMENTARY_ROLE"
          docker compose exec -T airflow-webserver airflow variables set ELEMENTARY_SCHEMA "$ELEMENTARY_SCHEMA"
          docker compose exec -T airflow-webserver airflow variables set ELEMENTARY_USER "$ELEMENTARY_USER"
          docker compose exec -T airflow-webserver airflow variables set ELEMENTARY_WAREHOUSE "$ELEMENTARY_WAREHOUSE"
          docker compose exec -T airflow-webserver airflow variables set PROJECT_ROOT_DIR_AIRFLOW_VAR "$PROJECT_ROOT_DIR_AIRFLOW_VAR"
          docker compose exec -T airflow-webserver airflow variables set SNOWFLAKE_ACCOUNT "$SNOWFLAKE_ACCOUNT"
          docker compose exec -T airflow-webserver airflow variables set SNOWFLAKE_DATABASE "$SNOWFLAKE_DATABASE"
          docker compose exec -T airflow-webserver airflow variables set SNOWFLAKE_ENV "$SNOWFLAKE_ENV"
          docker compose exec -T airflow-webserver airflow variables set SNOWFLAKE_PASSWORD "$SNOWFLAKE_PASSWORD"
          docker compose exec -T airflow-webserver airflow variables set SNOWFLAKE_ROLE "$SNOWFLAKE_ROLE"
          docker compose exec -T airflow-webserver airflow variables set SNOWFLAKE_SCHEMA_MART "$SNOWFLAKE_SCHEMA_MART"
          docker compose exec -T airflow-webserver airflow variables set SNOWFLAKE_SCHEMA_RAW "$SNOWFLAKE_SCHEMA_RAW"
          docker compose exec -T airflow-webserver airflow variables set SNOWFLAKE_USER "$SNOWFLAKE_USER"
          docker compose exec -T airflow-webserver airflow variables set SNOWFLAKE_WAREHOUSE "$SNOWFLAKE_WAREHOUSE"
          echo "All Airflow Variables set successfully."

    environment:
      name: production
      url: http://localhost:8080/ # Replace with your actual Airflow URL

  # Job to create and upload Elementary Report
  generate-and-upload-elementary-report:
    runs-on: ubuntu-latest
    needs: deploy-airflow-environment # Make sure the Airflow variables are set
    permissions:
      pages: write # Permissions required to deploy to GitHub Pages
      id-token: write # Required for OIDC authentication
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Log in to Docker Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.DOCKER_REGISTRY_URL }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10" # Make sure the Python version matches the Airflow Dockerfile

      - name: Install dbt and Elementary
        run: |
          pip install dbt-snowflake elementary-data # Install necessary packages
          echo "/home/runner/.local/bin" >> $GITHUB_PATH # Make sure dbt and edr CLI are in PATH

      - name: Create dbt profiles.yml
        run: |
          mkdir -p ~/.dbt
          cat <<EOF > ~/.dbt/profiles.yml
          ${{ vars.DBT_PROJECT_NAME }}:
            target: ${{ vars.SNOWFLAKE_ENV }}
            outputs:
              ${{ vars.SNOWFLAKE_ENV }}:
                type: snowflake
                account: ${{ secrets.SNOWFLAKE_ACCOUNT }}
                user: ${{ secrets.SNOWFLAKE_USER }}
                password: ${{ secrets.SNOWFLAKE_PASSWORD }}
                role: ${{ vars.SNOWFLAKE_ROLE }}
                warehouse: ${{ vars.SNOWFLAKE_WAREHOUSE }}
                database: ${{ vars.SNOWFLAKE_DATABASE }}
                schema: ${{ vars.SNOWFLAKE_SCHEMA_RAW }}
                threads: 1
                client_session_keep_alive: False
          elementary: # Profile cho Elementary
            target: ${{ vars.ELEMENTARY_ENV }}
            outputs:
              ${{ vars.ELEMENTARY_ENV }}:
                type: snowflake
                account: ${{ secrets.ELEMENTARY_ACCOUNT }}
                user: ${{ secrets.ELEMENTARY_USER }}
                password: ${{ secrets.ELEMENTARY_PASSWORD }}
                role: ${{ vars.ELEMENTARY_ROLE }}
                warehouse: ${{ vars.ELEMENTARY_WAREHOUSE }}
                database: ${{ vars.ELEMENTARY_DATABASE }}
                schema: ${{ vars.ELEMENTARY_SCHEMA }}
                threads: 1
                client_session_keep_alive: False
          EOF
          echo "dbt profiles.yml created."

      - name: Run dbt commands and generate Elementary report
        run: |
          set -ex # Print the command and exit if there is an error
          cd ${{ vars.DBT_FOLDER_NAME }} # Navigate to your dbt project folder
          dbt deps
          dbt seed # Run seed if you have seed files
          dbt run
          dbt test
          edr report --profiles-dir ~/.dbt --profile-target ${{ vars.ELEMENTARY_ENV }}
          echo "Elementary report generated."

      - name: Ensure Elementary report exists # Check for file existence
        run: |
          REPORT_PATH="${{ vars.DBT_FOLDER_NAME }}/edr_target/elementary_report.html"
          if [ ! -f "$REPORT_PATH" ]; then
            echo "Error: Elementary report not found at $REPORT_PATH!"
            exit 1
          fi
          echo "Elementary report found at $REPORT_PATH."

      - name: Upload Elementary Report as Artifact
        uses: actions/upload-artifact@v4
        with:
          name: elementary-report
          path: ${{ vars.DBT_FOLDER_NAME }}/edr_target/elementary_report.html
          retention-days: 1 # Keep artifact for 1 day to save space

  # Job to deploy Elementary Report to GitHub Pages
  deploy-github-pages:
    runs-on: ubuntu-latest
    needs: generate-and-upload-elementary-report # Depends on the report generation job
    permissions:
      contents: read # Repo read permission is required to load action
      pages: write # Permissions required to deploy to GitHub Pages
      id-token: write # Required for OIDC authentication
    environment:
      name: github-pages # Default environment name for GitHub Pages
      url: ${{ steps.deployment.outputs.page_url }} # GitHub Pages URL after deployment
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download Elementary Report artifact
        uses: actions/download-artifact@v4
        with:
          name: elementary-report
          path: ./elementary-report # Download artifact to this folder on runner

      - name: Setup Pages
        uses: actions/configure-pages@v5 # Configure GitHub Pages environment

      - name: Upload artifact to Pages
        uses: actions/upload-pages-artifact@v3.0.1 # Specify action to upload artifact to Pages
        with:
          path: "./elementary-report" # Path to the folder containing the report HTML file

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4 # Deploy content to GitHub Pages
